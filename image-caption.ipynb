{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image caption generation using mxnet\n",
    "\n",
    "This tutorial shows how to write mxnet code for image caption generation. The main goal is to produce a caption given an image. For e.g., \n",
    "\n",
    "![](testimage.jpg)\n",
    "A possible caption for this image can be **Surfer in the ocean riding a large wave**\n",
    "\n",
    "We would use a basic image caption model by implementing the **Show and Tell: A Neural Image Caption Generator,  Vinyals et al., 2015** The basic network is shown below:\n",
    "\n",
    "![](networkcaption.png)\n",
    "\n",
    "For training, we would use [MSCOCO](http://mscoco.org/dataset/#overview) dataset. The dataset contains a set of images each with upto 5 different captions. The network needs a feature vector extracted using any CNN (resnet, VGG) as input. It also needs the caption input (set of words mapped to an embedding that has the same dimension as the image feature vector). These inputs are extracted for a subset of the images and kept at [caption data pickle file](https://s3.amazonaws.com/gurumurthys-mxnet-data/data_image_caption/captiondata10k.pickle). The pickle file contains the feature vector for each image, the vocabulary index, the corresponding caption for each image as a set of indexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from mxnet.test_utils import download\n",
    "\n",
    "pickle_file_url = \"https://s3.amazonaws.com/gurumurthys-mxnet-data/data_image_caption/captiondata10k.pickle\"\n",
    "download(pickle_file_url,overwrite=True)\n",
    "pickle_file_url = \"https://s3.amazonaws.com/gurumurthys-mxnet-data/data_image_caption/captiondataval10k.pickle\"\n",
    "download(pickle_file_url,overwrite=True)\n",
    "\n",
    "[allwords, allindexes, vocabwords, vocabids, _] = pickle.load(open('captiondata10k.pickle', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = allwords.keys()[0]\n",
    "print 'feature vector: ', allwords[key][0]\n",
    "print 'caption indexes: ', allwords[key][1]\n",
    "print 'imgid: ', allindexes[key]\n",
    "key = vocabwords.keys()[0]\n",
    "print 'word -> index: ', key, '->', vocabwords[key]\n",
    "key = vocabids.keys()[0]\n",
    "print 'index -> word: ', key, '->', vocabids[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "module that defines lstm network that is used for image captioning\n",
    "'''\n",
    "from collections import namedtuple\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "LSTMState = namedtuple(\"LSTMState\", [\"c\", \"h\"])\n",
    "LSTMParam = namedtuple(\"LSTMParam\", [\"i2h_weight\", \"i2h_bias\",\n",
    "                                     \"h2h_weight\", \"h2h_bias\"])\n",
    "LSTMModel = namedtuple(\"LSTMModel\", [\"rnn_exec\", \"symbol\",\n",
    "                                     \"init_states\", \"last_states\",\n",
    "                                     \"forward_state\", \"backward_state\",\n",
    "                                     \"seq_data\", \"seq_labels\", \"seq_outputs\",\n",
    "                                     \"param_blocks\"])\n",
    "\n",
    "\n",
    "def lstmcell(num_hidden, indata, prev_state, param, seqidx, layeridx):\n",
    "    '''\n",
    "    Defines an LSTM cell\n",
    "    Args:\n",
    "        num_hidden: number of hidden units\n",
    "        indata: input data to LSTM cell\n",
    "        prev_state: previous state vector\n",
    "        param: parameter for this LSTM (weights and biases)\n",
    "        seqidx: sequence id\n",
    "        layeridx: layer index (0 - first layer, 1 - second layer). Useful for\n",
    "        bi-directional LSTM\n",
    "    Returns:\n",
    "        LSTM cell object\n",
    "    '''\n",
    "    dropout = 0.3\n",
    "    indata = mx.sym.Dropout(data=indata, p=dropout)\n",
    "    i2h = mx.sym.FullyConnected(data=indata,\n",
    "                                weight=param.i2h_weight,\n",
    "                                bias=param.i2h_bias,\n",
    "                                num_hidden=num_hidden * 4,\n",
    "                                name=\"t%d_l%d_i2h\" % (seqidx, layeridx))\n",
    "    h2h = mx.sym.FullyConnected(data=prev_state.h,\n",
    "                                weight=param.h2h_weight,\n",
    "                                bias=param.h2h_bias,\n",
    "                                num_hidden=num_hidden * 4,\n",
    "                                name=\"t%d_l%d_h2h\" % (seqidx, layeridx))\n",
    "    gates = i2h + h2h\n",
    "    slice_gates = mx.sym.SliceChannel(gates, num_outputs=4,\n",
    "                                      name=\"t%d_l%d_slice\" %\n",
    "                                      (seqidx, layeridx))\n",
    "    in_gate = mx.sym.Activation(slice_gates[0], act_type=\"sigmoid\")\n",
    "    in_transform = mx.sym.Activation(slice_gates[1], act_type=\"tanh\")\n",
    "    forget_gate = mx.sym.Activation(slice_gates[2], act_type=\"sigmoid\")\n",
    "    out_gate = mx.sym.Activation(slice_gates[3], act_type=\"sigmoid\")\n",
    "    next_c = (forget_gate * prev_state.c) + (in_gate * in_transform)\n",
    "    next_h = out_gate * next_c\n",
    "\n",
    "    return LSTMState(c=next_c, h=next_h)\n",
    "\n",
    "def build_lstm_network(seq_len, input_size, num_hidden, num_embed, num_label,\n",
    "                       prediction=False):\n",
    "    '''\n",
    "    Build the LSTM network\n",
    "    Args:\n",
    "        seq_len: length of the sequence - number of times to unroll\n",
    "        input_size: input vector dimension\n",
    "        num_hidden: number of hiddent units\n",
    "        num_embed: output dimension for the embedding unit\n",
    "        num_label: output dimension for the fully-connected unit\n",
    "        prediction: True if used for prediction, False if for training\n",
    "    Returns:\n",
    "        LSTM network symbol\n",
    "    '''\n",
    "    embed_weight = mx.sym.Variable(\"embed_weight\")\n",
    "    cls_weight = mx.sym.Variable(\"cls_weight\")\n",
    "    cls_bias = mx.sym.Variable(\"cls_bias\")\n",
    "\n",
    "    data = mx.sym.Variable('data')\n",
    "    label = mx.sym.Variable('softmax_label')\n",
    "    veclabel = mx.sym.Variable('veclabel')\n",
    "\n",
    "    name = 'l0'\n",
    "    param = LSTMParam(i2h_weight=mx.sym.Variable(name+\"_i2h_weight\"),\n",
    "                      i2h_bias=mx.sym.Variable(name+\"_i2h_bias\"),\n",
    "                      h2h_weight=mx.sym.Variable(name+\"_h2h_weight\"),\n",
    "                      h2h_bias=mx.sym.Variable(name+\"_h2h_bias\"))\n",
    "    lstm_state = LSTMState(c=mx.sym.Variable(name+\"_init_c\"),\n",
    "                           h=mx.sym.Variable(name+\"_init_h\"))\n",
    "    allsm = []\n",
    "    # label indices\n",
    "    labelidx = mx.sym.SliceChannel(data=label, num_outputs=seq_len,\n",
    "                                   squeeze_axis=1)\n",
    "    # label one-hot vector\n",
    "    labelvec = mx.sym.SliceChannel(data=veclabel, num_outputs=seq_len,\n",
    "                                   squeeze_axis=1)\n",
    "    output = ''\n",
    "    targetlen = seq_len\n",
    "    if prediction:\n",
    "        # increase seq_len to generate till stop words during testing\n",
    "        # it is a hack for now\n",
    "        targetlen = seq_len + 10\n",
    "    for seqidx in range(targetlen):\n",
    "        k = seqidx\n",
    "        # testing may use more than seq_len, hence reuse the last input\n",
    "        # as dummy labels for softmax\n",
    "        if k >= seq_len:\n",
    "            k = seq_len - 1\n",
    "        # first iteration use image feature as input\n",
    "        if k == 0:\n",
    "            hidden = data\n",
    "        else:\n",
    "            # if in prediction mode and not in first iteration use the\n",
    "            # system output generated in previous timestep as input\n",
    "            if prediction & (k > 1):\n",
    "                embed = mx.sym.Embedding(data=output,\n",
    "                                         input_dim=input_size,\n",
    "                                         weight=embed_weight,\n",
    "                                         output_dim=num_embed, name='embed')\n",
    "            else:\n",
    "                embed = mx.sym.Embedding(data=labelvec[k-1],\n",
    "                                         input_dim=input_size,\n",
    "                                         weight=embed_weight,\n",
    "                                         output_dim=num_embed, name='embed')\n",
    "            hidden = embed\n",
    "\n",
    "        next_state = lstmcell(num_hidden, indata=hidden,\n",
    "                              prev_state=lstm_state,\n",
    "                              param=param, seqidx=k, layeridx=0)\n",
    "        hidden = next_state.h\n",
    "        lstm_state = next_state\n",
    "        if k == 0:\n",
    "            continue\n",
    "        pred = mx.sym.FullyConnected(data=hidden, num_hidden=num_label,\n",
    "                                     weight=cls_weight,\n",
    "                                     bias=cls_bias, name='pred')\n",
    "        softmax_output = mx.sym.SoftmaxOutput(data=pred, label=labelidx[k],\n",
    "                                              name='softmax')\n",
    "        output = mx.sym.argmax(softmax_output, axis=1)\n",
    "        allsm.append(softmax_output)\n",
    "\n",
    "    allsm = mx.sym.Concat(*allsm, dim=1)  # pylint: disable=star-args\n",
    "    softmax_output = mx.sym.reshape(allsm, shape=(-1, num_label))\n",
    "    return (softmax_output,\n",
    "            ['veclabel', 'l0_init_h', 'l0_init_c', 'data'],\n",
    "            ['softmax_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "module that defines bucketing data iter\n",
    "'''\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet.io import DataBatch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a bucket data iterator\n",
    "\n",
    "Let us first built a bucket iterator to iterate over training samples. The function *default_gen_buckets* will generate a list of buckets based on the set of captions in the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_gen_buckets(allwords, batch_size):\n",
    "    '''\n",
    "    Generate buckets based on data. This method generates a list of buckets\n",
    "    and the length of those buckets based on the input\n",
    "    Args:\n",
    "        allwords: all the sentences (set of words) that are part of the data\n",
    "        batch_size: batch size to check if a particular bucket has that many\n",
    "        elements\n",
    "    Returns:\n",
    "        returns the generated buckets\n",
    "    '''\n",
    "    len_dict = {}\n",
    "    max_len = -1\n",
    "    for key in allwords:\n",
    "        words = allwords[key][1]\n",
    "        if len(words) == 0:\n",
    "            continue\n",
    "        if len(words) > max_len:\n",
    "            max_len = len(words)\n",
    "        if len(words) in len_dict:\n",
    "            len_dict[len(words)] += 1\n",
    "        else:\n",
    "            len_dict[len(words)] = 1\n",
    "    buckets = []\n",
    "    for length, num in len_dict.items():\n",
    "        if num >= batch_size:\n",
    "            buckets.append(length)\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BucketIter(mx.io.DataIter):\n",
    "    '''\n",
    "    Class that defines the data iter for image captioning module\n",
    "    '''\n",
    "    def __init__(self, captionf, vocabf, featuref, batch_size=1):\n",
    "        '''\n",
    "        Init function for the class\n",
    "        Args:\n",
    "            captionf: pickle filename that has all the captions\n",
    "            vocabf: pickle filename that has the vocabulary words\n",
    "            featuref: feature filename that has feature vector for each\n",
    "            image in the dataset\n",
    "            batch_size: batch size for training data\n",
    "        '''\n",
    "        super(BucketIter, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # load datafiles\n",
    "        [self.allwords, self.allindexes, self.vocabwords, self.vocabids, \\\n",
    "         self.unknown_id] = pickle.load(open(captionf, 'r'))\n",
    "\n",
    "        # generate buckets\n",
    "        buckets = default_gen_buckets(self.allwords, batch_size)\n",
    "        buckets.sort()\n",
    "        self.buckets = buckets\n",
    "        # assing default bucket - ideally should be the largest bucket\n",
    "        self.default_bucket_key = buckets[0]\n",
    "\n",
    "        # Assign data to their corresponding bucket\n",
    "        self.databkt = [[] for _ in buckets]\n",
    "        self.cursor = {}\n",
    "        self.num_data_bkt = {}\n",
    "        for idx in self.allwords:\n",
    "            strs = self.allwords[idx][1]\n",
    "            for i, bkt in enumerate(buckets):\n",
    "                if bkt == len(strs):\n",
    "                    self.databkt[i].append(idx)\n",
    "                    break\n",
    "        \n",
    "        # initialize bucket specific parameters, the current index into \n",
    "        # the bucket and the remaining number of elements in the bucket\n",
    "        for i, bkt in enumerate(buckets):\n",
    "            self.cursor[i] = -1\n",
    "            self.num_data_bkt[i] = len(self.databkt[i])\n",
    "\n",
    "    # iterator variables\n",
    "        self.epoch = 0\n",
    "        self.bidx = 0\n",
    "        self.data, self.label, _ = self.read(self.bidx)\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def bucket_key(self):\n",
    "        '''\n",
    "        bucket key for bucketiter module\n",
    "        '''\n",
    "        return self.buckets[self.bidx]\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        \"\"\"The name and shape of data provided by this iterator\"\"\"\n",
    "        res = [(k, tuple(list(self.data[k].shape[0:]))) for k in self.data]\n",
    "        return res\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        \"\"\"The name and shape of label provided by this iterator\"\"\"\n",
    "        res = [(k, tuple(list(self.label[k].shape[0:]))) for k in self.label]\n",
    "        return res\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        data iter reset\n",
    "        '''\n",
    "        for index, _ in enumerate(self.cursor):\n",
    "            self.cursor[index] = -1\n",
    "        self.epoch += 1\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"return one dict which contains \"data\" and \"label\" \"\"\"\n",
    "        if self.iter_next():\n",
    "            # select one random bucket out of all the ones that has\n",
    "            # > batch_size remaining samples\n",
    "            rem = [i for i, _ in enumerate(self.buckets)\n",
    "                   if (len(self.databkt[i])-self.cursor[i]) > self.batch_size]\n",
    "            bidx = np.random.randint(0, len(rem))\n",
    "            bidx = rem[bidx]\n",
    "            # read the samples from the bucket\n",
    "            self.data, self.label, imgids = self.read(bidx)\n",
    "            # prepare as databatch to return\n",
    "            res = DataBatch(provide_data=self.provide_data,\n",
    "                            provide_label=self.provide_label,\n",
    "                            bucket_key=self.buckets[self.bidx],\n",
    "                            data=[mx.nd.array(self.data['veclabel']),\n",
    "                                  mx.nd.array(self.data['l0_init_h']),\n",
    "                                  mx.nd.array(self.data['l0_init_c']),\n",
    "                                  mx.nd.array(self.data['data'])],\n",
    "                            label=[mx.nd.array(self.label['softmax_label'])],\n",
    "                            pad=0, index=None)\n",
    "            #return res, imgids\n",
    "            return res\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def iter_next(self):\n",
    "        '''\n",
    "        check if next iteration can be done\n",
    "        '''\n",
    "        for i, _ in enumerate(self.buckets):\n",
    "            if self.cursor[i] + self.batch_size < self.num_data_bkt[i]:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def read(self, bidx):\n",
    "        '''\n",
    "        read the next set of data based on bucket index\n",
    "        Args:\n",
    "            bidx: bucket index\n",
    "        '''\n",
    "        self.bidx = bidx\n",
    "        data_array = []\n",
    "        allimgids = []\n",
    "        label = []\n",
    "        labelvec = []\n",
    "        index = 0\n",
    "        while 1:\n",
    "            self.cursor[bidx] += 1\n",
    "            data = self.get_data(bidx)\n",
    "            imgid = self.get_imgids(bidx)\n",
    "            labels = self.get_label(bidx)\n",
    "            if len(labels) == 0:\n",
    "                continue\n",
    "            data_array.append(data)\n",
    "            allimgids.append(imgid)\n",
    "            labela = []\n",
    "            labelveca = []\n",
    "            for labelidx in labels:\n",
    "                labelarray = np.zeros((len(self.vocabwords)+1), dtype='int')\n",
    "                labelarray[labelidx] = 1\n",
    "                labela.append(labelarray)\n",
    "                labelveca.append(labelidx)\n",
    "            label.append(labela)\n",
    "            labelvec.append(labelveca)\n",
    "            index += 1\n",
    "            if index > (self.batch_size-1):\n",
    "                break\n",
    "\n",
    "        darray = np.vstack(data_array)\n",
    "        imgidarray = np.vstack(allimgids)\n",
    "        # this is also defined in trainmodel.py - need to consolidate\n",
    "        num_hidden = 512\n",
    "\n",
    "        data = {}\n",
    "        data['l0_init_h'] = np.zeros((darray.shape[0], num_hidden),\n",
    "                                     dtype='float')\n",
    "        data['l0_init_c'] = np.zeros((darray.shape[0], num_hidden),\n",
    "                                     dtype='float')\n",
    "        data['data'] = darray\n",
    "        data['veclabel'] = np.array(labelvec)\n",
    "\n",
    "        finallabel = {}\n",
    "        finallabel['softmax_label'] = np.asarray(label)\n",
    "\n",
    "        return (data, finallabel, imgidarray)\n",
    "\n",
    "    def get_data(self, bidx):\n",
    "        '''\n",
    "        Returns the feature vector based on the current cursor\n",
    "        and bucket index\n",
    "        Args:\n",
    "            bidx: bucket index\n",
    "        '''\n",
    "        idx = self.databkt[bidx][self.cursor[bidx]]\n",
    "        return self.allwords[idx][0]\n",
    "\n",
    "    def get_imgids(self, bidx):\n",
    "        '''\n",
    "        Returns the feature vector based on the current cursor\n",
    "        and bucket index\n",
    "        Args:\n",
    "            bidx: bucket index\n",
    "        '''\n",
    "        idx = self.databkt[bidx][self.cursor[bidx]]\n",
    "        return self.allindexes[idx]\n",
    "\n",
    "    def get_label(self, bidx):\n",
    "        '''\n",
    "        Returns the label vector based on the current cursor\n",
    "        and bucket index\n",
    "        Args:\n",
    "            bidx: bucket index\n",
    "        '''\n",
    "        idx = self.databkt[bidx][self.cursor[bidx]]\n",
    "        return self.allwords[idx][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "main code for training image captioning model\n",
    "'''\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custommetric(label, pred):\n",
    "    '''\n",
    "    Simple metric that outputs the fraction of correct word predictions\n",
    "    to the total number of words\n",
    "    Args:\n",
    "        label: ground truth label\n",
    "        pred: predicted output\n",
    "    Returns:\n",
    "        accuracy metric\n",
    "    '''\n",
    "    # shift by one word to match prediction\n",
    "    label = label[:, 1:, :]\n",
    "\n",
    "    pred = np.reshape(pred, label.shape)\n",
    "    label = np.argmax(label, axis=2)\n",
    "    pred = np.argmax(pred, axis=2)\n",
    "    return float(np.sum(pred == label))/np.sum(label >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 200\n",
    "    NUM_HIDDEN = 512\n",
    "    NUM_EPOCH = 300\n",
    "    GENERATE_GRAPH = False\n",
    "    DATADIR = '.'\n",
    "\n",
    "    # pylint: disable=C0103\n",
    "    data_train = BucketIter(DATADIR+'/captiondata10k.pickle',\n",
    "                                         DATADIR+'/vocab.pickle',\n",
    "                                         DATADIR+'/features.pickle',\n",
    "                                         batch_size=BATCH_SIZE)\n",
    "    if DEBUG:\n",
    "        print 'training data loaded ....'\n",
    "        print data_train.provide_data, data_train.provide_label\n",
    "\n",
    "    INPUT_SIZE = data_train.provide_data[3][1][1]\n",
    "    NUM_LABEL = len(data_train.vocabwords)+1\n",
    "    if DEBUG:\n",
    "        print INPUT_SIZE, NUM_LABEL\n",
    "\n",
    "    data_val = BucketIter(DATADIR+'/captiondataval10k.pickle',\n",
    "                                       DATADIR+'/vocab.pickle',\n",
    "                                       DATADIR+'/featuresval.pickle',\n",
    "                                       batch_size=BATCH_SIZE)\n",
    "    if DEBUG:\n",
    "        print 'validation data loaded ....'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    contexts = [mx.context.gpu(i) for i in range(1)]\n",
    "\n",
    "    # this is needed for the bucketing module\n",
    "    def sym_gen(seq_len):\n",
    "        '''\n",
    "        needed for bucketing module, network generated based on seq_len\n",
    "        Args:\n",
    "            seq_len: length of the current sequence\n",
    "        Returns:\n",
    "            Symbolic network\n",
    "        '''\n",
    "        return build_lstm_network(seq_len, INPUT_SIZE, NUM_HIDDEN, INPUT_SIZE,\n",
    "                                  NUM_LABEL)\n",
    "    model = mx.mod.BucketingModule(sym_gen, data_train.default_bucket_key,\n",
    "                                   context=contexts)\n",
    "\n",
    "    model.bind(data_shapes=data_train.provide_data,\n",
    "               label_shapes=data_train.provide_label)\n",
    "    model.init_params(initializer=mx.init.Normal(sigma=0.01))\n",
    "\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(level=logging.DEBUG, format=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(data_train, data_val, num_epoch=NUM_EPOCH, optimizer='adam',\n",
    "              optimizer_params={'learning_rate': 0.001},\n",
    "              eval_metric=mx.metric.CustomMetric(custommetric),\n",
    "              epoch_end_callback=mx.callback.do_checkpoint(\"imagecaption\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model to generate a caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "module that generates features for images using resnet\n",
    "'''\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import cv2\n",
    "import mxnet as mx\n",
    "from collections import namedtuple\n",
    "\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    '''\n",
    "    download the file given the url\n",
    "    Args:\n",
    "        url: path for the filename\n",
    "    '''\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "def get_model(prefix, epoch):\n",
    "    '''\n",
    "    get the model with prefix and epoch\n",
    "    Args:\n",
    "        prefix: model prefix\n",
    "        epoch: trained model - epoch\n",
    "    '''\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "\n",
    "def get_image(filename):\n",
    "    '''\n",
    "    return the image based on filename after resizing it to 224x224 to be\n",
    "    fit for reset format\n",
    "    Args:\n",
    "        filename: filename of the image\n",
    "    '''\n",
    "    img = cv2.imread(filename)  # read image in b,g,r order\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # change to r,g,b order\n",
    "    img = cv2.resize(img, (224, 224))  # resize to 224*224 to fit model\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)  # change to (channel, height, width)\n",
    "    img = img[np.newaxis, :]  # extend to (example, channel, heigth, width)\n",
    "    return img\n",
    "\n",
    "\n",
    "class Resnet(object):\n",
    "    '''\n",
    "    Resnet class to construct reset model object\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Download the model from mxnet database and constructs the network\n",
    "        for prediction\n",
    "        '''\n",
    "        url = 'http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50'\n",
    "        get_model(url, 0)\n",
    "        sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)\n",
    "        all_layers = sym.get_internals()\n",
    "        sym3 = all_layers['flatten0_output']\n",
    "        mod3 = mx.mod.Module(symbol=sym3, label_names=None, context=mx.cpu())\n",
    "        mod3.bind(for_training=False, data_shapes=[('data', (1, 3, 224, 224))])\n",
    "        mod3.set_params(arg_params, aux_params)\n",
    "        self.mod3 = mod3\n",
    "\n",
    "    def gen_features(self, img_path):\n",
    "        '''\n",
    "        generate features given an image\n",
    "        Args:\n",
    "            img_path: full path to the image\n",
    "        '''\n",
    "        img = get_image(img_path)\n",
    "        self.mod3.forward(Batch([mx.nd.array(img)]))\n",
    "        return self.mod3.get_outputs()[0].asnumpy()\n",
    "\n",
    "\n",
    "def get_feature(imgfname):\n",
    "    '''\n",
    "    Returns the feature for the image\n",
    "    Args:\n",
    "        imagefname: full path to the image\n",
    "    '''\n",
    "    network = Resnet()\n",
    "    return network.gen_features(imgfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "generate captions for an image\n",
    "'''\n",
    "import numpy as np\n",
    "import sys\n",
    "import mxnet as mx\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pylint: disable=star-args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %matplotlib inline\n",
    "    NUM_LSTM_LAYER = 1\n",
    "    BATCH_SIZE = 1\n",
    "    # pylint: disable=C0103\n",
    "    imgfname = \"data/testimage.jpg\"\n",
    "\n",
    "    SEQ_LEN = 25\n",
    "\n",
    "    sym, arg_params, aux_params = \\\n",
    "        mx.model.load_checkpoint(\"imagecaption\", 78)\n",
    "\n",
    "    NUM_HIDDEN = arg_params['l0_h2h_weight'].shape[1]\n",
    "    INPUT_SIZE = arg_params['l0_h2h_weight'].shape[0]\n",
    "    NUM_LABEL = arg_params['cls_weight'].shape[0]\n",
    "    sym, _, _ = build_lstm_network(SEQ_LEN, INPUT_SIZE, NUM_HIDDEN,\n",
    "                                   INPUT_SIZE, NUM_LABEL, prediction=True)\n",
    "\n",
    "    init_c = [('l%d_init_c' % l, (BATCH_SIZE, NUM_HIDDEN))\n",
    "              for l in range(NUM_LSTM_LAYER)]\n",
    "    init_h = [('l%d_init_h' % l, (BATCH_SIZE, NUM_HIDDEN))\n",
    "              for l in range(NUM_LSTM_LAYER)]\n",
    "    data_shape = [(\"data\", (BATCH_SIZE, 2048))]\n",
    "    label_shape = [(\"veclabel\",\n",
    "                    (BATCH_SIZE, SEQ_LEN, ))]\n",
    "    label_shape1 = [(\"softmax_label\",\n",
    "                     (BATCH_SIZE, SEQ_LEN, NUM_LABEL))]\n",
    "\n",
    "    f = get_feature(imgfname)\n",
    "    input_data = mx.nd.array(f)\n",
    "\n",
    "    veclabel = mx.nd.zeros((BATCH_SIZE, SEQ_LEN))\n",
    "    veclabel[0][0] = 0\n",
    "    input_shapes = dict(init_c+init_h+data_shape+label_shape+label_shape1)\n",
    "\n",
    "    executor = sym.simple_bind(ctx=mx.gpu(), **input_shapes)\n",
    "\n",
    "    for key in executor.arg_dict.keys():\n",
    "        if key in arg_params:\n",
    "            arg_params[key].copyto(executor.arg_dict[key])\n",
    "\n",
    "    state_name = []\n",
    "    for i in range(NUM_LSTM_LAYER):\n",
    "        state_name.append(\"l%d_init_c\" % i)\n",
    "    states_dict = dict(zip(state_name, executor.outputs[1:]))\n",
    "    input_arr = mx.nd.zeros(data_shape[0][1])\n",
    "\n",
    "    for key in states_dict.keys():\n",
    "        executor.arg_dict[key][:] = 0.\n",
    "\n",
    "    input_data.copyto(executor.arg_dict[\"data\"])\n",
    "    veclabel.copyto(executor.arg_dict[\"veclabel\"])\n",
    "\n",
    "    executor.forward()\n",
    "\n",
    "    for key in states_dict.keys():\n",
    "        states_dict[key].copyto(executor.arg_dict[key])\n",
    "\n",
    "    prob = executor.outputs[0].asnumpy()\n",
    "\n",
    "    img = cv2.imread(imgfname)[:,:,::-1]\n",
    "    plt.imshow(img)\n",
    "    [_, _, _, vocab, _]  = pickle.load(open(VOCABF, 'r'))\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        p = np.reshape(prob, (-1, SEQ_LEN+9, 9955))\n",
    "        p = np.argmax(p, axis=2)[index, :]\n",
    "        str1 = ''\n",
    "        index = 0\n",
    "        for i in p:\n",
    "            if i == 2:\n",
    "                break\n",
    "            str1 = str1 + vocab[i] + ' '\n",
    "            index += 1\n",
    "    print str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgfname)[:,:,::-1]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
